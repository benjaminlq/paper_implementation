{"cells":[{"cell_type":"code","source":["!pip install --upgrade datasets --quiet"],"metadata":{"id":"mkBLOOYcjpir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount(\"/content/drive\")\n","%cd /content/drive/MyDrive\n","\n","PARENT_DIR = os.getcwd()\n","MAIN_DIR = os.path.join(\n","    PARENT_DIR, \"Implement Classic Papers\", \"BERT\"\n",")\n","DATA_DIR = os.path.join(\n","    PARENT_DIR, \"Data\", \"Text\", \"bookcorpus\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rk1Sa5Ew3yb8","executionInfo":{"status":"ok","timestamp":1730352699382,"user_tz":-480,"elapsed":2749,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"c3f45d4a-c20a-4c18-a421-2ef57573c4fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5EGGkcmC9F5A"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math\n","import torch.nn.functional as F\n","import random\n","from torch.optim import AdamW\n","from torch.optim.lr_scheduler import LambdaLR\n","\n","from typing import List, Union, Callable, Optional, Dict\n","from transformers import AutoTokenizer\n","from datasets import load_dataset\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","\n","MAIN_DIR = os.getcwd()\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"markdown","metadata":{"id":"vZaop3QkikWB"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":313,"referenced_widgets":["cd2437be68ac430eba1b6004fc4c721d","29007f962ac2413d954886dd9dfcd7d5","b5e89fa2789947618e1166d3c47bf17b","5314b9f2efb046db9a996b45a24325b2","eba7f3d4369a445797f52b87458447ba","babca6dd2ee7449eb23967a60340ee3c","e5b739a31fe54969b4c7521b9f11bf14","75a6dbe89cd541f5b8fcd250269f1de7","ab13f2c03c384ade9aebb07cc5640aa9","27332345220c4b2fa4c791ab99aed121","2f9d1fd5463448dda0c5423fb6239574","f25b91d25ba046eda53853bc01ed07a9","f3be25e3da034d72b6e84c688a90b56d","f30014d481f845439bfb3d1328736b7c","d1c12ed9ff6b4925924058e02a396139","3019e82eeb414c89b53f28da50684618","51582acdd2f540838cda04deb916448e","5d83c870d60d421b85f0eb8372c79117","7dbbac402dd34d5890c0cc07c250a189","ca8b6a063185469dab132b014e9f492e","1ab0c1d4bec044308303094c5af54546","140837decc764d44a6ee980949bb7dda","1bb3d8306bdc408da31faac11ab63527","49a5bc0b8b8f44509a2d25990752ff5c","05823fd9579e49ceb4622e406faf2991","995cab9878bf450fbc138e45ce30558c","52918d14e1574c61a73f513438eb8979","1217759b0f8e4d2babe388289e2d20b0","f83fe689e94f4d54aecd351d89eea2ac","baf3ce2b0ea7421480b5cbe029073e78","aef0adc158fb400d9d7d7665b4be41f8","6b793293371c4829ae181e15d4d69a69","64b18daa06964f31a6c40fcf4e9526b9","4c79f7567cf344948f1db02d4b2a9f24","ea548483a968404cbaeb9762260a65a8","86bb4f8050a04f94a5f8a9996c52c695","c929df380ab6479192791d6e51def86d","5632344a925a4322ad6cce0dab4ab712","799e27ea12564fcaae8adec76cccc8fe","a76d7232bc0147298457c202a85224aa","317ee3e5199d48f6bba883ec93d687c9","860f9cb8ba1544039ee985e57afbf3c3","a9495dd2bcef4ab2823f8340935cc3f7","2681797e21044b21a8efc9eee829ef29"]},"id":"ESfDmPQ5ikWD","executionInfo":{"status":"ok","timestamp":1730352714855,"user_tz":-480,"elapsed":5759,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"0099e072-e86e-481a-c965-825affb8a014"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd2437be68ac430eba1b6004fc4c721d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f25b91d25ba046eda53853bc01ed07a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bb3d8306bdc408da31faac11ab63527"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c79f7567cf344948f1db02d4b2a9f24"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    # os.path.join(MAIN_DIR, \"tokenizers\", \"google-bert\", \"bert-large-uncased\")\n","    \"bert-large-uncased\"\n","    )"]},{"cell_type":"markdown","metadata":{"id":"U7fnubDlikWE"},"source":["# Pretraining\n","\n","- Masked Language Modelling (MLM)\n","- Next Sentence Prediction (NSP)"]},{"cell_type":"markdown","source":["## Architecture"],"metadata":{"id":"rmYTBWeeTroh"}},{"cell_type":"markdown","metadata":{"id":"4WmJ2AUEikWF"},"source":["### Embeddings\n","- Token embeddings: For each token in vocabulary\n","- Absolute positional embedding: Using sinusoidal function to model absolute position in the sentence sequence.\n","- Segment Embedding: Used for next sentence prediction and NLI tasks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"22p-SaYJikWF"},"outputs":[],"source":["class SinusoidalPositionalEncoding(nn.Module):\n","    def __init__(\n","        self, d_model: int, dropout: float=0.1, max_len: int=512\n","    ):\n","        super(SinusoidalPositionalEncoding, self).__init__()\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(p=dropout)\n","        pe = torch.zeros(size=(max_len, d_model)) # (max_len, d_model)\n","        const_term = math.log(10000) / d_model\n","        div_terms = torch.exp(-torch.arange(0, d_model, 2) * const_term) # (d_model//2)\n","        positions = torch.arange(0, max_len).unsqueeze(1) # (max_len, 1)\n","        pe[:, ::2] = torch.sin(positions*div_terms)  # sin(pos * div_term)\n","        pe[:, 1::2] = torch.cos(positions*div_terms)  # sin(pos * div_term)\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(\n","        self, inputs: torch.Tensor\n","    ):\n","        # Input sequence: (batch_size, seq_length)\n","        seq_len = inputs.size(1)\n","        x = self.pe[:, : seq_len, :].requires_grad_(False)\n","        return self.dropout(x)\n","\n","class TokenEmbeddings(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int,\n","        vocab_size: int=30522,\n","        padding_idx: int=0\n","    ):\n","        super(TokenEmbeddings, self).__init__()\n","        self.d_model, self.vocab_size = d_model, vocab_size\n","        self.embeddings = nn.Embedding(\n","            num_embeddings=vocab_size,\n","            embedding_dim=d_model, padding_idx=padding_idx\n","        )\n","\n","    def forward(\n","        self, inputs: torch.Tensor\n","    ):\n","        return self.embeddings(inputs) * math.sqrt(self.d_model)\n","\n","class SegmentEmbedding(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768,\n","        padding_idx: int = 2,\n","    ):\n","        super(SegmentEmbedding, self).__init__()\n","        self.padding_idx = padding_idx\n","        self.embedding = nn.Embedding(\n","                3, embedding_dim=d_model, padding_idx=padding_idx\n","            )\n","\n","    def forward(\n","        self,\n","        token_types_id: torch.Tensor, # (batch_size, seq_len)\n","        attn_mask: Optional[torch.Tensor] = None\n","        ):\n","        token_types_id = token_types_id.masked_fill(\n","            attn_mask==0, self.padding_idx\n","        )\n","        segment_embeddings = self.embedding(token_types_id)\n","        return segment_embeddings # (batch_size, seq_len, d_model)\n","\n","class BERTEmbedding(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768,\n","        vocab_size: int = 30522,\n","        use_segment_embedding: bool = False,\n","        dropout: float = 0.1,\n","        token_padding_idx: int = 0,\n","        segment_padding_idx: int = 2\n","    ):\n","        super(BERTEmbedding, self).__init__()\n","        self.token_embedding = TokenEmbeddings(\n","            d_model=d_model,\n","            vocab_size=vocab_size,\n","            padding_idx=token_padding_idx\n","            )\n","        self.positional_embedding = SinusoidalPositionalEncoding(\n","            d_model=d_model, max_len=512\n","        )\n","        self.segment_embedding = None\n","        if use_segment_embedding:\n","            self.segment_embedding = SegmentEmbedding(\n","                d_model=d_model, padding_idx=segment_padding_idx\n","            )\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(\n","        self,\n","        inputs: torch.Tensor, # (batch_size, seq_len)\n","        token_type_ids: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor] = None,\n","    ) -> torch.Tensor:\n","        token_embeddings = self.token_embedding(inputs)\n","        pos_embeddings = self.positional_embedding(inputs)\n","        embeddings = token_embeddings + pos_embeddings\n","        if self.segment_embedding:\n","            embeddings = embeddings + self.segment_embedding(token_type_ids, attn_mask)\n","        return self.dropout(embeddings)"]},{"cell_type":"markdown","metadata":{"id":"IMWIb-hBikWH"},"source":["### Model Architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qh8fG04T9_Ap"},"outputs":[],"source":["class GroupAttentionHead(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int,\n","        d_q: int,\n","        d_k: int,\n","        d_v: int,\n","        n_heads: int = 1,\n","        dropout: float = 0.1\n","    ):\n","        super(GroupAttentionHead, self).__init__()\n","        self.d_q, self.d_k, self.d_v = d_q, d_k, d_v\n","        self.Q = nn.ModuleList([nn.Linear(d_model, d_q) for _ in range(n_heads)])\n","        self.K = nn.Linear(d_model, d_k)\n","        self.V = nn.Linear(d_model, d_v)\n","        self.dropout = dropout\n","\n","    def forward(\n","        self,\n","        query: torch.Tensor, key: torch.Tensor, value: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor]=None,\n","        dropout: Optional[float]=None,\n","        is_causal: bool=False\n","    ):\n","        \"\"\"Calculate attention values for a single attention head.\n","        For self attention, q = k = v; Dimension = (batch_size, seq_len, d_model)\n","        For seq2seq cross attention\n","        - q = output of masked attention previous component of the decoder. Dimension = (batch_size, tgt_seq_len, d_model)\n","        - k = v = output of the encoder. Dimension = (batch_size, src_seq_len, d_model)\n","        \"\"\"\n","        dropout = dropout or self.dropout\n","        query = torch.cat(\n","            [q(query).unsqueeze(1) for q in self.Q], dim = 1\n","        ) # (batch_size, n_groups, seq_len, d_q)\n","        key = self.K(key).unsqueeze(1) # (batch_size, 1, seq_len, d_k)\n","        value = self.V(value).unsqueeze(1) # (batch_size, 1, seq_len, d_v)\n","        if isinstance(attn_mask, torch.Tensor):\n","            attn_mask = attn_mask.unsqueeze(1).unsqueeze(1).type(torch.bool)\n","\n","        values = F.scaled_dot_product_attention(\n","            query, key, value, attn_mask, dropout, is_causal\n","            )\n","\n","        return values\n","\n","class MultiHeadedAttention(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768,\n","        n_heads: int = 12,\n","        n_groups: int = 12,\n","        dropout: float = 0.1,\n","        d_v: Optional[int] = None\n","    ):\n","        super(MultiHeadedAttention, self).__init__()\n","        self.d_model = d_model\n","        self.n_heads = n_heads\n","        self.n_groups = n_groups\n","        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n","        assert n_heads % n_groups == 0, \"Total number of heads must be divisible by number of groups\"\n","        self.heads_per_group = n_heads // n_groups\n","        self.d_q = d_model // n_heads\n","        self.d_k = self.d_q\n","        self.d_v = d_v or self.d_q\n","        self.attn_heads = nn.ModuleList(\n","            [\n","                GroupAttentionHead(d_model, self.d_q, self.d_k, self.d_v, n_heads=self.heads_per_group, dropout=dropout)\n","                for _ in range(n_groups)\n","                ]\n","            )\n","        self.O = nn.Linear(self.d_v * self.n_heads, self.d_model)\n","\n","    def forward(\n","        self,\n","        query: torch.Tensor, key: torch.Tensor, value: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor]=None,\n","        dropout: Optional[float]=None,\n","        is_causal: bool=False\n","    ):\n","        batch_size = query.size(0)\n","        tgt_seq_len = value.size(1)\n","        values = torch.cat(\n","            [\n","                att_head(\n","                    query, key, value,\n","                    attn_mask=attn_mask, dropout=dropout, is_causal=is_causal)\n","                for att_head in self.attn_heads\n","                ], dim = 1\n","            ).transpose(1, 2) # (bs, tgt_seq_len, n_heads * n_groups, d_v)\n","        values = values.contiguous().view(batch_size, tgt_seq_len, -1)\n","        return self.O(values)\n","\n","class PointwiseFeedForward(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768,\n","        d_feedfoward: Optional[int] = None,\n","        activation: str = \"gelu\",\n","    ):\n","        super(PointwiseFeedForward, self).__init__()\n","        self.d_feedforward = d_feedfoward or d_model * 4\n","        self.linear1 = nn.Linear(d_model, self.d_feedforward)\n","        self.linear2 = nn.Linear(self.d_feedforward, d_model)\n","        self.activation = getattr(nn.functional, activation)\n","\n","    def forward(\n","        self, inputs: torch.Tensor\n","    ):\n","        x = self.linear1(inputs)\n","        x = self.linear2(self.activation(x))\n","        return x\n","\n","class ResidualLayer(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768,\n","        dropout: float = 0.1\n","    ):\n","        super(ResidualLayer, self).__init__()\n","        self.d_model = d_model\n","        self.layer_norm = nn.LayerNorm(normalized_shape=d_model, eps=1e-5)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(\n","        self, inputs: torch.Tensor, sublayer: Callable\n","    ):\n","        return self.layer_norm(inputs + self.dropout(sublayer(inputs)))\n","\n","class EncoderBlock(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int=768,\n","        n_heads: int=12,\n","        n_groups: int=3,\n","        dropout: float=0.1,\n","        d_v: Optional[int] = None,\n","        d_feedfoward: Optional[int] = None,\n","        activation: str = \"gelu\",\n","    ):\n","        super(EncoderBlock, self).__init__()\n","        self.d_model = d_model\n","        self.multihead_group_attention = MultiHeadedAttention(\n","            d_model=d_model, n_heads=n_heads, n_groups=n_groups, dropout=dropout, d_v=d_v,\n","        )\n","        self.feedforward = PointwiseFeedForward(d_model=d_model, d_feedfoward=d_feedfoward, activation=activation)\n","        self.att_residual = ResidualLayer(d_model=d_model)\n","        self.ff_residual = ResidualLayer(d_model=d_model)\n","\n","    def forward(\n","        self,\n","        inputs: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor] = None,\n","        is_causal: bool = False\n","    ):\n","        x = self.att_residual(\n","            inputs,\n","            lambda x: self.multihead_group_attention(\n","                x, x, x, attn_mask=attn_mask, is_causal=is_causal\n","            )\n","        )\n","        x = self.ff_residual(x, self.feedforward)\n","        return x\n","\n","class TransformerEncoder(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int=768,\n","        n_layers: int=12,\n","        n_heads: int=12,\n","        n_groups: int=3,\n","        dropout: float=0.1,\n","        d_v: Optional[int] = None,\n","        d_feedfoward: Optional[int] = None,\n","        activation: str = \"gelu\",\n","    ):\n","        super(TransformerEncoder, self).__init__()\n","        self.d_model = d_model\n","        self.layers = nn.ModuleList(\n","            [\n","                EncoderBlock(\n","                    d_model=d_model, n_heads=n_heads, n_groups=n_groups, dropout=dropout, d_v=d_v,\n","                    d_feedfoward=d_feedfoward, activation=activation)\n","                for _ in range(n_layers)\n","                ]\n","        )\n","\n","    def forward(\n","        self,\n","        x: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor] = None,\n","        is_causal: bool = False\n","    ):\n","        for layer in self.layers:\n","            x = layer(x, attn_mask=attn_mask, is_causal=is_causal)\n","        return x\n","\n","class BERTBackbone(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int=768,\n","        vocab_size: int=30522,\n","        n_layers: int=12,\n","        n_heads: int=12,\n","        n_groups: int=3,\n","        dropout: float=0.1,\n","        d_v: Optional[int] = None,\n","        d_feedfoward: Optional[int] = None,\n","        activation: str = \"gelu\",\n","        use_segment_embedding: bool = False\n","    ):\n","        super(BERTBackbone, self).__init__()\n","\n","        self.embedding = BERTEmbedding(\n","            d_model=d_model,\n","            vocab_size=vocab_size,\n","            use_segment_embedding=use_segment_embedding,\n","            dropout=dropout\n","        )\n","\n","        self.encoder = TransformerEncoder(\n","            d_model=d_model,\n","            n_layers=n_layers,\n","            n_heads=n_heads,\n","            n_groups=n_groups,\n","            dropout=dropout,\n","            d_v=d_v,\n","            d_feedfoward=d_feedfoward,\n","            activation=activation\n","        )\n","\n","        self.d_model = d_model\n","        self.vocab_size = vocab_size\n","\n","        # Initialize weights\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def forward(\n","        self,\n","        inputs: torch.Tensor, # (batch_size, seq_len)\n","        token_type_ids: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor] = None,\n","        is_causal: bool = False\n","    ):\n","        x = self.embedding(\n","            inputs=inputs, token_type_ids=token_type_ids, attn_mask=attn_mask\n","        )\n","        x = self.encoder(\n","            x,\n","            attn_mask=attn_mask.type(torch.float),\n","            is_causal=is_causal\n","            )\n","        return x\n","\n","class MaskLanguageHead(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768,\n","        vocab_size: int = 30522\n","    ):\n","        super(MaskLanguageHead, self).__init__()\n","        self.d_model = d_model\n","        self.proj = nn.Linear(\n","            d_model, vocab_size\n","        )\n","\n","    def forward(\n","        self,\n","        inputs: torch.Tensor\n","    ):\n","        return F.log_softmax(self.proj(inputs), dim=-1)\n","\n","class NextSentencePredictionHead(nn.Module):\n","    def __init__(\n","        self,\n","        d_model: int = 768\n","    ):\n","        super(NextSentencePredictionHead, self).__init__()\n","        self.proj = nn.Linear(d_model, 2)\n","\n","    def forward(\n","        self,\n","        inputs: torch.Tensor\n","    ):\n","        cls_embs = inputs[:, 0, :] # (batch_size, d_model) -> (batch_size, 2)\n","        return F.log_softmax(self.proj(cls_embs), dim=-1)\n","\n","class BERTForPretraining(nn.Module):\n","    def __init__(\n","        self,\n","        bert: BERTBackbone,\n","        vocab_size: Optional[int] = None\n","    ):\n","        super(BERTForPretraining, self).__init__()\n","        self.bert = bert\n","        self.vocab_size = vocab_size or self.bert.vocab_size\n","        self.d_model = self.bert.d_model\n","        self.mlm = MaskLanguageHead(\n","            self.d_model, self.vocab_size\n","        )\n","        self.nsp = NextSentencePredictionHead(\n","            self.d_model\n","        )\n","\n","    def forward(\n","        self,\n","        input_ids: torch.Tensor,\n","        token_type_ids: torch.Tensor,\n","        attn_mask: Optional[torch.Tensor] = None,\n","        is_causal: bool = False,\n","        **kwargs,\n","    ):\n","        final_hiddens = self.bert(\n","            inputs = input_ids,\n","            token_type_ids = token_type_ids,\n","            attn_mask = attn_mask,\n","            is_causal = is_causal\n","        )\n","        return (self.mlm(final_hiddens), self.nsp(final_hiddens))"]},{"cell_type":"markdown","metadata":{"id":"oDY4CWFUikWK"},"source":["## Data Preparation\n","\n","For BERT, pretraining used BookCorpus (800M tokens) and Wikipedia (2.5B tokens). Here we only used a subset of BookCorpus.\n","\n","- Bookcorpus\n","- NSP: 50% samples use next text spans, 50% samples used randomly sampled text spans\n","- MLM: 15% of content tokens are masked\n","    - 80% with [MASK] tokens\n","    - 10% with a random tokens\n","    - 10% unchanged"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpP3lZPoikWL"},"outputs":[],"source":["class BookCorpusPretrainDataset(Dataset):\n","    def __init__(\n","        self,\n","        corpus: List[str],\n","        tokenizer: Callable,\n","        corpus_len: Optional[List[int]] = None,\n","        seq_len: int = 128,\n","        prob: float = 0.15,\n","        mask_prob: float = 0.80,\n","        random_prob: float = 0.10,\n","        **kwargs\n","    ):\n","        self.corpus = corpus\n","        self.corpus_len = corpus_len\n","        if not self.corpus_len:\n","            batch_size = 256\n","            self.corpus_len = []\n","\n","            for start_idx in tqdm(range(0, len(bookcorpus), batch_size)):\n","                batch_data = tokenizer(self.corpus[start_idx:start_idx+batch_size][\"text\"], add_special_tokens=False)[\"input_ids\"]\n","                for seq in batch_data:\n","                    self.corpus_len.append(len(seq))\n","\n","        self.tokenizer = tokenizer\n","        self.seq_len = seq_len\n","        self.vocab_size = tokenizer.vocab_size\n","        self.special_token_map = {}\n","        for token_type, token_str in self.tokenizer.special_tokens_map.items():\n","            token_id = self.tokenizer.convert_tokens_to_ids(token_str)\n","            self.special_token_map[token_type] = (token_str, token_id)\n","\n","        self.non_special_token_ids = [token_id for token_id in range(self.vocab_size) if token_id not in self.tokenizer.all_special_ids]\n","        self.prob = prob\n","        self.mask_prob = mask_prob\n","        self.random_prob = random_prob\n","\n","    def get_text_span(self, idx, max_len: int):\n","        sentences = []\n","        token_counts = 0\n","        if self.corpus_len[idx] > max_len:\n","            return sentences\n","\n","        sentences.append(self.corpus[idx])\n","        token_counts += self.corpus_len[idx]\n","\n","        curr_idx = idx\n","        while token_counts < max_len and curr_idx < (len(self) - 1):\n","            next_sentence = self.corpus[curr_idx + 1]\n","            curr_idx += 1\n","            if token_counts + self.corpus_len[curr_idx] <= max_len:\n","                sentences.append(next_sentence)\n","                token_counts += self.corpus_len[curr_idx]\n","            else:\n","                break\n","\n","        return sentences\n","\n","    def get_seq_len(self, input_str):\n","        return len(self.tokenizer.encode(input_str, add_special_tokens=False))\n","\n","    def __len__(self):\n","        return len(self.corpus)\n","\n","    def __sample_mask(\n","        self,\n","        input_ids: List[int],\n","        prob: Optional[float] = None,\n","        mask_prob: Optional[float] = None,\n","        random_prob: Optional[float] = None,\n","    ):\n","        prob = prob or self.prob\n","        mask_prob = mask_prob or self.mask_prob\n","        random_prob = random_prob or self.random_prob\n","\n","        masked_seq = []\n","        masked_labels = []\n","        for token_id in input_ids:\n","            if token_id not in self.tokenizer.all_special_ids:\n","                if random.random() < 0.15:\n","                    prob = random.random()\n","                    if prob < mask_prob: # Change to MASK token (80%)\n","                        masked_seq.append(self.special_token_map[\"mask_token\"][1])\n","                    elif prob < (mask_prob + random_prob): # Change to a random token (10%)\n","                        masked_seq.append(random.choice(self.non_special_token_ids))\n","                    else: # Does not change (10%)\n","                        masked_seq.append(token_id)\n","                    masked_labels.append(token_id)\n","                else:\n","                    masked_seq.append(token_id)\n","                    masked_labels.append(self.special_token_map[\"pad_token\"][1])\n","            else:\n","                masked_seq.append(token_id)\n","                masked_labels.append(self.special_token_map[\"pad_token\"][1])\n","        return (masked_seq, masked_labels)\n","\n","    def __getitem__(self, idx):\n","        if idx == (len(self) - 1):\n","            idx = random.randint(0, len(self) - 2)\n","        while True:\n","            sentences = self.get_text_span(idx, max_len=self.seq_len - 3)\n","            if len(sentences) >= 2:\n","                break\n","            else:\n","                idx = random.randint(0, len(self) - 2)\n","\n","        max_len = random.randint(1, len(sentences) - 1)\n","\n","        split_threshold = random.randint(1, max_len)\n","        nsp_prob = random.random()\n","        sent_A = \" \".join(sentences[:split_threshold])\n","        if nsp_prob > 0.5:\n","            sent_B = \" \".join(sentences[split_threshold:])\n","            nsp_label = 0\n","        else: # Need to sample a random span\n","            while True:\n","                random_span = self.get_text_span(random.randint(0, len(self)-1), max_len=self.seq_len - self.get_seq_len(sent_A) - 3)\n","                if len(random_span) >= 2:\n","                    break\n","                else:\n","                    split_threshold -= 1\n","                    sent_A = \" \".join(sentences[:split_threshold])\n","\n","            random_split_threshold = random.randint(1, len(random_span) - 1)\n","            sent_B = \" \".join(random_span[random_split_threshold:])\n","            nsp_label = 1\n","\n","        tokens_info = self.tokenizer(\n","            sent_A, sent_B, truncation=False, padding='max_length', max_length=self.seq_len\n","        )\n","        input_ids = tokens_info[\"input_ids\"]\n","        attn_mask = tokens_info[\"attention_mask\"]\n","        token_type_ids = tokens_info[\"token_type_ids\"]\n","\n","        input_ids, labels = self.__sample_mask(input_ids=input_ids)\n","        return {\n","            \"input_ids\": torch.tensor(input_ids),\n","            \"attn_mask\": torch.tensor(attn_mask),\n","            \"token_type_ids\": torch.tensor(token_type_ids),\n","            \"mlm_label\": torch.tensor(labels),\n","            \"nsp_label\": torch.tensor([nsp_label]),\n","        }"]},{"cell_type":"markdown","source":["## Trainer Class"],"metadata":{"id":"RFCvkEHvUgdE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4vwgLbQikWM"},"outputs":[],"source":["def custom_lr_schedule(\n","    step_no: int, warm_up: int = 10000, total_steps: int = 100000\n","):\n","    post_warm_up_steps = total_steps - warm_up\n","    if step_no == 0:\n","        step_no = 1\n","    if step_no <= warm_up:\n","        return step_no / warm_up\n","    else:\n","        return (total_steps - step_no) / post_warm_up_steps\n","\n","class TrainState:\n","    n_steps: int = 0\n","    n_updates: int = 0\n","    train_loss = {\n","        \"mlm\": {\"step\": [], \"epoch\": []},\n","        \"nsp\": {\"step\": [], \"epoch\": []}\n","        }\n","    val_loss = {\n","        \"mlm\": {\"step\": [], \"epoch\": []},\n","        \"nsp\": {\"step\": [], \"epoch\": []}\n","        }\n","    lr = []\n","\n","class BERTTrainer:\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        optimizer_args: Dict,\n","        sampling_args: Dict,\n","        device: str,\n","    ):\n","        self.model = model.to(device)\n","        self.optimizer_args = optimizer_args\n","        self.sampling_args = sampling_args\n","        self.device = device\n","        self.train_state = TrainState()\n","        self.accumulation_steps = optimizer_args[\"accumulation_steps\"]\n","\n","        self.optimizer = AdamW(\n","            params = self.model.parameters(),\n","            lr = optimizer_args[\"lr\"],\n","            betas = optimizer_args[\"betas\"],\n","            weight_decay = optimizer_args[\"weight_decay\"]\n","        )\n","\n","        self.scheduler = LambdaLR(\n","            optimizer=self.optimizer,\n","            lr_lambda=lambda x: custom_lr_schedule(\n","                x, warm_up=optimizer_args[\"warmup\"], total_steps=optimizer_args[\"total_steps\"]\n","                )\n","            )\n","        self.loss_criterion = nn.NLLLoss(ignore_index=0)\n","        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n","\n","    def run_epoch(\n","        self,\n","        epoch: int,\n","        dataloader: DataLoader,\n","        train_state: Optional[TrainState] = None,\n","        max_steps: Optional[int] = None,\n","        is_train: bool = True\n","    ):\n","        train_state = train_state or self.train_state\n","        if is_train:\n","            self.model.train()\n","        else:\n","            self.model.eval()\n","\n","        mode = \"train\" if is_train else \"eval\"\n","\n","        data_iter = tqdm(\n","            enumerate(dataloader),\n","            desc=\"EP_%s:%d\" % (mode, epoch),\n","            total=len(dataloader),\n","            bar_format=\"{l_bar}{r_bar}\"\n","        )\n","\n","        epoch_mlm_loss = 0.0\n","        epoch_nsp_loss = 0.0\n","        epoch_nsp_preds = 0\n","        epoch_nsp_correct = 0\n","        epoch_steps = 0\n","\n","        for idx, batch in data_iter:\n","            if train_state.n_steps >= max_steps:\n","                break\n","\n","            batch = {k: v.to(self.device) for k, v in batch.items()}\n","            input_ids = batch[\"input_ids\"]\n","            token_type_ids = batch[\"token_type_ids\"]\n","            attn_mask = batch[\"attn_mask\"]\n","            mlm_labels = batch[\"mlm_label\"]\n","            nsp_labels = batch[\"nsp_label\"]\n","\n","            mlm_outs, nsp_outs = self.model(\n","                input_ids=input_ids,\n","                token_type_ids=token_type_ids,\n","                attn_mask=attn_mask,\n","            )\n","\n","            mlm_loss = self.loss_criterion(mlm_outs.view(-1, mlm_outs.shape[-1]), mlm_labels.view(-1))\n","            nsp_loss = self.loss_criterion(nsp_outs, nsp_labels.view(-1))\n","            loss = mlm_loss + nsp_loss\n","\n","            nsp_preds = nsp_outs.argmax(dim=-1)\n","            nsp_correct = nsp_preds.eq(nsp_labels.view(-1)).sum().item()\n","\n","            epoch_nsp_preds += nsp_preds.size(0)\n","            epoch_nsp_correct += nsp_correct\n","\n","            if is_train:\n","                self.train_state.n_steps += 1\n","                loss.backward()\n","                if self.train_state.n_steps % self.accumulation_steps == 0:\n","                    self.optimizer.step()\n","                    self.optimizer.zero_grad()\n","                    self.train_state.n_updates += 1\n","\n","                lr = self.optimizer.param_groups[0][\"lr\"]\n","                self.train_state.lr.append(lr)\n","                self.train_state.train_loss[\"mlm\"][\"step\"].append(mlm_loss.item())\n","                self.train_state.train_loss[\"nsp\"][\"step\"].append(mlm_loss.item())\n","                self.scheduler.step()\n","\n","            else:\n","                self.train_state.val_loss[\"mlm\"][\"step\"].append(mlm_loss.item())\n","                self.train_state.val_loss[\"nsp\"][\"step\"].append(mlm_loss.item())\n","\n","            epoch_mlm_loss += mlm_loss.item()\n","            epoch_nsp_loss += nsp_loss.item()\n","            epoch_steps += 1\n","\n","            if (idx + 1) % 100 == 0:\n","                avg_mlm_loss = epoch_mlm_loss / epoch_steps\n","                avg_nsp_loss = epoch_nsp_loss / epoch_steps\n","                avg_nsp_acc = epoch_nsp_correct / epoch_nsp_preds\n","\n","                print(\n","                    f\"Epoch {epoch} - Step {self.train_state.n_steps}, mode {mode}: avg_mlm_loss={avg_mlm_loss}, avg_nsp_loss={avg_nsp_loss}, avg_nsp_acc={avg_nsp_acc}\")\n","\n","        avg_mlm_loss = epoch_mlm_loss / epoch_steps\n","        avg_nsp_loss = epoch_nsp_loss / epoch_steps\n","        avg_nsp_acc = epoch_nsp_correct / epoch_nsp_preds\n","\n","        if is_train:\n","            train_state.train_loss[\"mlm\"][\"epoch\"].append(avg_mlm_loss)\n","            train_state.train_loss[\"nsp\"][\"epoch\"].append(avg_nsp_loss)\n","        else:\n","            train_state.val_loss[\"mlm\"][\"epoch\"].append(avg_mlm_loss)\n","            train_state.val_loss[\"nsp\"][\"epoch\"].append(avg_nsp_loss)\n","\n","        print(\n","            f\"Whole Epoch {epoch}, mode {mode}: avg_mlm_loss={avg_mlm_loss}, avg_nsp_loss={avg_nsp_loss}, avg_nsp_acc={avg_nsp_acc}\")\n","\n","    def train(\n","        self,\n","        n_step: int,\n","        dataloader: DataLoader,\n","        max_steps: Optional[int] = None,\n","        is_train: bool = True\n","        ):\n","        max_steps = self.train_state.n_steps + n_step\n","        epoch_no = 0\n","        while self.train_state.n_steps < max_steps:\n","            epoch_no += 1\n","            self.run_epoch(\n","                epoch=epoch_no,\n","                dataloader=dataloader,\n","                train_state=self.train_state,\n","                max_steps=max_steps,\n","                is_train=is_train\n","            )"]},{"cell_type":"markdown","source":["## Pretrain !!!"],"metadata":{"id":"GS7p6t81VB67"}},{"cell_type":"markdown","source":["### Pretrain Arguments\n","\n","- Using a linear LR scheduler for warm-up (10000 steps) and decay (LR linearly reduced to 0 from max LR).\n","- 2 stage:\n","    - Stage 1: 90% steps - Use 128 sequence length\n","    - Stage 2: 10% steps - Use 512 sequence length"],"metadata":{"id":"sFuMVxPvVDsv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0axbD6J5ikWM"},"outputs":[],"source":["# model_args = dict(\n","#     d_model=32,\n","#     n_layers=2,\n","#     n_heads=4,\n","#     n_groups=1,\n","#     dropout=0.1,\n","#     use_segment_embedding=True\n","# ) # DEBUG\n","\n","model_args = dict(\n","    d_model=768,\n","    n_layers=12,\n","    n_heads=12,\n","    n_groups=4,\n","    dropout=0.1,\n","    use_segment_embedding=True\n",") # BERT BASE\n","\n","optimizer_args = dict(\n","    lr=1e-4,\n","    betas=(0.9, 0.999),\n","    weight_decay=0.01,\n","    warmup=10000,\n","    total_steps=100000,\n","    accumulation_steps=1\n",")\n","\n","sampling_args = dict(\n","    prob=0.15,\n","    mask_prob=0.80,\n","    random_prob=0.10,\n",")\n","\n","training_stages = [\n","    dict(n_steps=90000, batch_size=32, seq_len=128), # Stage 1\n","    dict(n_steps=10000, batch_size=32, seq_len=512) # Stage 2\n","    ]"]},{"cell_type":"code","source":["bookcorpus_dataset = load_dataset(os.path.join(DATA_DIR))[\"train\"]\n","\n","bookcorpus = bookcorpus_dataset[:100000][\"text\"]\n","\n","batch_size = 256\n","corpus_len = []\n","\n","for start_idx in tqdm(range(0, len(bookcorpus), batch_size)):\n","    batch_data = tokenizer(bookcorpus[start_idx:start_idx+batch_size], add_special_tokens=False)[\"input_ids\"]\n","    for seq in batch_data:\n","        corpus_len.append(len(seq))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzTvt5Hm8Xyf","executionInfo":{"status":"ok","timestamp":1730354047854,"user_tz":-480,"elapsed":45881,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"a1be98b6-dd5f-4469-f66c-1ff1ce7af274"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 391/391 [00:05<00:00, 68.74it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lQ4BRMeFikWN","executionInfo":{"status":"ok","timestamp":1730356500245,"user_tz":-480,"elapsed":790,"user":{"displayName":"Le Quan","userId":"09348170862113886974"}},"outputId":"db07e69e-d68f-4890-cfd2-0bc03dfbe2c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total Parameters: 2006332\n"]}],"source":["bert_backbone = BERTBackbone(**model_args)\n","bert_pretrain_model = BERTForPretraining(\n","    bert=bert_backbone,\n",")\n","model = bert_pretrain_model\n","bert_trainer = BERTTrainer(\n","    model=model,\n","    optimizer_args=optimizer_args,\n","    sampling_args=sampling_args,\n","    device=DEVICE,\n",")"]},{"cell_type":"code","source":["for stage in training_stages:\n","    bert_pretrain_dataset = BookCorpusPretrainDataset(\n","        corpus=bookcorpus,\n","        tokenizer=tokenizer,\n","        corpus_len=corpus_len,\n","        seq_len = stage[\"seq_len\"],\n","        **sampling_args\n","    )\n","    bert_pretrain_dataloader = DataLoader(\n","        dataset=bert_pretrain_dataset,\n","        batch_size=stage[\"batch_size\"],\n","        shuffle=True,\n","        num_workers=8,\n","        pin_memory=True,\n","        drop_last=True\n","    )\n","    torch.cuda.empty_cache()\n","    bert_trainer.train(\n","        n_step=stage[\"n_steps\"],\n","        dataloader=bert_pretrain_dataloader,\n","        is_train=True\n","    )"],"metadata":{"id":"ilmMPYinDaSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_dir = os.path.join(\n","    MAIN_DIR, \"artifacts\", \"checkpoints\"\n",")\n","os.makedirs(output_dir, exist_ok=True)\n","torch.save(model.bert.state_dict(), os.path.join(output_dir, \"pretrain_checkpoint.pt\"))"],"metadata":{"id":"hDgI6ImHf4j3"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"cd2437be68ac430eba1b6004fc4c721d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_29007f962ac2413d954886dd9dfcd7d5","IPY_MODEL_b5e89fa2789947618e1166d3c47bf17b","IPY_MODEL_5314b9f2efb046db9a996b45a24325b2"],"layout":"IPY_MODEL_eba7f3d4369a445797f52b87458447ba"}},"29007f962ac2413d954886dd9dfcd7d5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_babca6dd2ee7449eb23967a60340ee3c","placeholder":"​","style":"IPY_MODEL_e5b739a31fe54969b4c7521b9f11bf14","value":"tokenizer_config.json: 100%"}},"b5e89fa2789947618e1166d3c47bf17b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75a6dbe89cd541f5b8fcd250269f1de7","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ab13f2c03c384ade9aebb07cc5640aa9","value":48}},"5314b9f2efb046db9a996b45a24325b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27332345220c4b2fa4c791ab99aed121","placeholder":"​","style":"IPY_MODEL_2f9d1fd5463448dda0c5423fb6239574","value":" 48.0/48.0 [00:00&lt;00:00, 1.43kB/s]"}},"eba7f3d4369a445797f52b87458447ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"babca6dd2ee7449eb23967a60340ee3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5b739a31fe54969b4c7521b9f11bf14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75a6dbe89cd541f5b8fcd250269f1de7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab13f2c03c384ade9aebb07cc5640aa9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27332345220c4b2fa4c791ab99aed121":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f9d1fd5463448dda0c5423fb6239574":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f25b91d25ba046eda53853bc01ed07a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f3be25e3da034d72b6e84c688a90b56d","IPY_MODEL_f30014d481f845439bfb3d1328736b7c","IPY_MODEL_d1c12ed9ff6b4925924058e02a396139"],"layout":"IPY_MODEL_3019e82eeb414c89b53f28da50684618"}},"f3be25e3da034d72b6e84c688a90b56d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51582acdd2f540838cda04deb916448e","placeholder":"​","style":"IPY_MODEL_5d83c870d60d421b85f0eb8372c79117","value":"config.json: 100%"}},"f30014d481f845439bfb3d1328736b7c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dbbac402dd34d5890c0cc07c250a189","max":571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ca8b6a063185469dab132b014e9f492e","value":571}},"d1c12ed9ff6b4925924058e02a396139":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ab0c1d4bec044308303094c5af54546","placeholder":"​","style":"IPY_MODEL_140837decc764d44a6ee980949bb7dda","value":" 571/571 [00:00&lt;00:00, 17.7kB/s]"}},"3019e82eeb414c89b53f28da50684618":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51582acdd2f540838cda04deb916448e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d83c870d60d421b85f0eb8372c79117":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dbbac402dd34d5890c0cc07c250a189":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ca8b6a063185469dab132b014e9f492e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ab0c1d4bec044308303094c5af54546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"140837decc764d44a6ee980949bb7dda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bb3d8306bdc408da31faac11ab63527":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49a5bc0b8b8f44509a2d25990752ff5c","IPY_MODEL_05823fd9579e49ceb4622e406faf2991","IPY_MODEL_995cab9878bf450fbc138e45ce30558c"],"layout":"IPY_MODEL_52918d14e1574c61a73f513438eb8979"}},"49a5bc0b8b8f44509a2d25990752ff5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1217759b0f8e4d2babe388289e2d20b0","placeholder":"​","style":"IPY_MODEL_f83fe689e94f4d54aecd351d89eea2ac","value":"vocab.txt: 100%"}},"05823fd9579e49ceb4622e406faf2991":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_baf3ce2b0ea7421480b5cbe029073e78","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aef0adc158fb400d9d7d7665b4be41f8","value":231508}},"995cab9878bf450fbc138e45ce30558c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b793293371c4829ae181e15d4d69a69","placeholder":"​","style":"IPY_MODEL_64b18daa06964f31a6c40fcf4e9526b9","value":" 232k/232k [00:00&lt;00:00, 1.07MB/s]"}},"52918d14e1574c61a73f513438eb8979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1217759b0f8e4d2babe388289e2d20b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f83fe689e94f4d54aecd351d89eea2ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"baf3ce2b0ea7421480b5cbe029073e78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef0adc158fb400d9d7d7665b4be41f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b793293371c4829ae181e15d4d69a69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64b18daa06964f31a6c40fcf4e9526b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c79f7567cf344948f1db02d4b2a9f24":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ea548483a968404cbaeb9762260a65a8","IPY_MODEL_86bb4f8050a04f94a5f8a9996c52c695","IPY_MODEL_c929df380ab6479192791d6e51def86d"],"layout":"IPY_MODEL_5632344a925a4322ad6cce0dab4ab712"}},"ea548483a968404cbaeb9762260a65a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_799e27ea12564fcaae8adec76cccc8fe","placeholder":"​","style":"IPY_MODEL_a76d7232bc0147298457c202a85224aa","value":"tokenizer.json: 100%"}},"86bb4f8050a04f94a5f8a9996c52c695":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_317ee3e5199d48f6bba883ec93d687c9","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_860f9cb8ba1544039ee985e57afbf3c3","value":466062}},"c929df380ab6479192791d6e51def86d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9495dd2bcef4ab2823f8340935cc3f7","placeholder":"​","style":"IPY_MODEL_2681797e21044b21a8efc9eee829ef29","value":" 466k/466k [00:00&lt;00:00, 1.07MB/s]"}},"5632344a925a4322ad6cce0dab4ab712":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"799e27ea12564fcaae8adec76cccc8fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a76d7232bc0147298457c202a85224aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"317ee3e5199d48f6bba883ec93d687c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"860f9cb8ba1544039ee985e57afbf3c3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9495dd2bcef4ab2823f8340935cc3f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2681797e21044b21a8efc9eee829ef29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}